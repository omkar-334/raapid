{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "import re\n",
    "import zipfile\n",
    "\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define Regex patterns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# start with an \"in\" tag and are followed by one or more \"nn\" tags.\n",
    "# PATTERN_1 = r\"\\bin\\b\\s+(\\bnn\\b\\s+)+\"\n",
    "PATTERN_1 = r\"(?<!\\S|-)in\\b\\s+(\\bnn\\b\\s+)+\"\n",
    "\n",
    "# start with an \"jj\" tag and are followed by one or more \"nn\" tags\n",
    "# PATTERN_2 = r\"\\bjj\\b\\s+(\\bnn\\b\\s+)+\"\n",
    "# the above regex did not work because '\\b' (word boundary) was matching other non-space characters like hypen. Example \"in-jj nn\" was matching but it should not.\n",
    "# in the new pattern, we are using negative lookbehind to ensure that the \"jj\" tag is not preceded by a non-space character or hyphen.\n",
    "PATTERN_2 = r\"(?<!\\S|-)jj\\b\\s+(\\bnn\\b\\s+)+\"\n",
    "EMAIL = \"omkarkabde@gmail.com\"\n",
    "\n",
    "patterns = {\"pattern_1\": PATTERN_1, \"pattern_2\": PATTERN_2}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since we are using regex to match the tags, and each match returns match.span() , we find the start positions for each tag and word separately, then create a mapping dictionary.  \n",
    "\n",
    "For example -   \n",
    "Sentence = \"She/pps looked/vbd at/in me/ppo provocatively/rb .\"  \n",
    "Words = \"She looked at me provocatively\"  \n",
    "Tags = \"pps vbd in ppo rb\"  \n",
    "\n",
    "```json\n",
    "{\n",
    "    0: 0,   # \"She\" -> \"pps\"\n",
    "    4: 4,   # \"looked\" -> \"vbd\"\n",
    "    10: 8,  # \"at\" -> \"in\"\n",
    "    13: 11, # \"me\" -> \"ppo\"\n",
    "    16: 15  # \"provocatively\" -> \"rb\"\n",
    "}\n",
    "```\n",
    "\n",
    "This helps us get the `begin` and `end` of the text, not just tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_match_dict(words, tags):\n",
    "    \"\"\"Creates a mapping of tag positions to word positions.\"\"\"\n",
    "    tag_length = 0\n",
    "    word_length = 0\n",
    "    match_dict = {0: 0}\n",
    "\n",
    "    for word, tag in zip(words, tags):\n",
    "        tag_length += len(tag) + 1\n",
    "        word_length += len(word) + 1\n",
    "        match_dict[tag_length] = word_length\n",
    "\n",
    "    return match_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This function creates an entry for each row of the dataset.  \n",
    "First split the sentence into words and tags, return words text and tags text.  \n",
    "Then create the `match_dict` and find matches for the given regex pattern.  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_entry(row, pattern):\n",
    "    \"\"\"Create an entry for a given row and pattern.\"\"\"\n",
    "    text = row[\"raw_text\"]\n",
    "\n",
    "    # separate the words\n",
    "    splits = text.split(\" \")\n",
    "    # separate the words and tags\n",
    "    words = [i.split(\"/\")[0] for i in splits]\n",
    "    tags = [i.split(\"/\")[1] for i in splits]\n",
    "\n",
    "    # create separate text sentences\n",
    "    tags_text, words_text = \" \".join(tags), \" \".join(words)\n",
    "\n",
    "    # initialize the entry with the row data\n",
    "    entry = row.to_dict()\n",
    "    entry.pop(\"raw_text\")\n",
    "    entry[\"sent_text\"] = words_text\n",
    "\n",
    "    match_dict = create_match_dict(words, tags)\n",
    "    matches = re.finditer(pattern, tags_text)\n",
    "\n",
    "    phrases = []\n",
    "    for match in matches:\n",
    "        phrase = {}\n",
    "        tag_begin, tag_end = match.span()\n",
    "        phrase[\"begin\"] = match_dict[tag_begin]\n",
    "        phrase[\"end\"] = match_dict[tag_end]\n",
    "        # map the tag positions to word positions\n",
    "        phrase[\"text\"] = words_text[phrase[\"begin\"] : phrase[\"end\"] - 1]\n",
    "        # remove the last space from the text\n",
    "        phrase[\"phrase_type\"] = match.group().removesuffix(\" \")\n",
    "        phrases.append(phrase)\n",
    "    entry[\"phrases\"] = phrases\n",
    "\n",
    "    return entry"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is just a basic function to create the jsons and zips from the dicts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_zip(pattern_dict, filename):\n",
    "    json_filename = f\"{filename}.json\"\n",
    "    with open(json_filename, \"w\", encoding=\"utf-8\") as f:\n",
    "        json.dump(pattern_dict, f, indent=4, ensure_ascii=False)\n",
    "\n",
    "    zip_filename = f\"{filename}.zip\"\n",
    "    with zipfile.ZipFile(zip_filename, \"w\", zipfile.ZIP_DEFLATED) as zipf:\n",
    "        zipf.write(json_filename, os.path.basename(json_filename))\n",
    "\n",
    "    print(f\"Created {zip_filename} containing {json_filename}\")\n",
    "\n",
    "\n",
    "def create_script_zip():\n",
    "    \"\"\"Function to zip the ipynb file\"\"\"\n",
    "    script_filename = \"task_b.ipynb\"\n",
    "    filename = f\"{EMAIL}.zip\"\n",
    "    with zipfile.ZipFile(filename, \"w\", zipfile.ZIP_DEFLATED) as zipf:\n",
    "        zipf.write(script_filename, os.path.basename(script_filename))\n",
    "\n",
    "    print(f\"Created {filename} containing {script_filename}\")\n",
    "    # os.remove(script_filename)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This function is the main one, It checks if the entry has any matching phrases then adds it to the json. and then creates the zips"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_pattern(pattern_name):\n",
    "    \"\"\"Create a zip file for the given pattern.\"\"\"\n",
    "    df = pd.read_csv(\"dataset_B.csv\")\n",
    "    pattern_dict = {}\n",
    "    pattern_dict[\"pattern\"] = pattern_name.replace(\"_\", \" \")\n",
    "    pattern = patterns[pattern_name]\n",
    "\n",
    "    sents = []\n",
    "    for idx, row in df.iterrows():\n",
    "        try:\n",
    "            entry = create_entry(row, pattern)\n",
    "            if len(entry[\"phrases\"]) > 0:\n",
    "                # print(f\"Entry: {entry}\")\n",
    "                sents.append(entry)\n",
    "        except Exception as e:\n",
    "            print(f\"ERROR --- {idx} --- {e}\")\n",
    "\n",
    "    pattern_dict[\"sents\"] = sents\n",
    "\n",
    "    filename = f\"{pattern_name}_{EMAIL}\"\n",
    "    create_zip(pattern_dict, filename)\n",
    "    return pattern_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run this function to get the json files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created pattern_1_omkarkabde@gmail.com.zip containing pattern_1_omkarkabde@gmail.com.json\n",
      "Created pattern_2_omkarkabde@gmail.com.zip containing pattern_2_omkarkabde@gmail.com.json\n",
      "Created omkarkabde@gmail.com.zip containing task_b.ipynb\n",
      "All patterns processed.\n"
     ]
    }
   ],
   "source": [
    "for pattern_name in patterns:\n",
    "    check_pattern(pattern_name)\n",
    "\n",
    "create_script_zip()\n",
    "print(\"All patterns processed.\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
